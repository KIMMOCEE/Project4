{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **📊 1. 관심 데이터 선정**\n",
        "\n",
        "> Smilegate AI에서 underscore와 협업하여 만든 데이터셋인 Korean UnSmile Dataset을 사용하였습니다.\n",
        "(https://github.com/smilegate-ai/korean_unsmile_dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R9xcxROOyBWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **❓ 2. 데이터 선정 이유**\n",
        "\n",
        "*   온라인 환경에서 익명성과 표현의 자유 뒤에 숨어 악의적인 발언으로 상대를 공격이 이전에 주된 악성 댓글이었다면 현재는 불특정 다수인 특정 집단에 대한 혐오 표현 사용까지 진행되는 중입니다.\n",
        "*   전자의 경우 피해자에겐 큰 정신적 고통이, 후자의 경우 분별없는 수용와 전파로 인한 사회적 인식 변화로 인해 집단 전체가 피해를 봅니다.\n",
        "\n",
        "\n",
        "> 현재 사용되는 혐오표현들은 의미없는 갈등과 혐오의 재생산을 만들어내 사회적으로 큰 악영향을 끼치는데 이는 포털사이트, 게임, 영상제작 등 다양한 분야에서의 컨텐츠나 서비스에서도 문제가 되는 것을 쉽게 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "r8l6Ijdyzbei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🧩 3. 데이터를 이용한 가설 수립**\n",
        "\n",
        "> 악성 댓글 / 혐오 표현을 사전에 검출, 차단함으로써, 사회적 문제에 대한 기업의 책임 문제 해결과 서비스의 품질 향상을 기대해 볼 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "vKSLgaAGzfjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🧹 4. 데이터 전처리**\n",
        "\n",
        "\n",
        "\n",
        "> 1번의 깃헙 링크에 들어가시면 데이터에 대한 많은 정보를 보실 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "-N5KD_GoziHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets==1.17.0"
      ],
      "metadata": {
        "id": "GEBZWLnEJRNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 가져오기\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('smilegate-ai/kor_unsmile')"
      ],
      "metadata": {
        "id": "eSpWkGuCfhGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISnlqnetJ5Bd",
        "outputId": "b0bf9374-f944-448f-d4ab-8e3d3b7f2f87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean': 1,\n",
              " 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " '개인지칭': 0,\n",
              " '기타 혐오': 0,\n",
              " '남성': 0,\n",
              " '문장': '일안하는 시간은 쉬고싶어서 그런게 아닐까',\n",
              " '성소수자': 0,\n",
              " '악플/욕설': 0,\n",
              " '여성/가족': 0,\n",
              " '연령': 0,\n",
              " '인종/국적': 0,\n",
              " '종교': 0,\n",
              " '지역': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsmile_labels = [\"여성/가족\",\"남성\",\"성소수자\",\"인종/국적\",\"연령\",\"지역\",\"종교\",\"기타 혐오\",\"악플/욕설\",\"clean\"]"
      ],
      "metadata": {
        "id": "Z4y3sTXNJcoc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05AwBZ5SUzZF",
        "outputId": "81c01a10-f27d-4d9f-896b-cd779f2a177e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (15005, 13), 'valid': (3737, 13)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🧠 5. 딥러닝 방식 적용**"
      ],
      "metadata": {
        "id": "F4wGA5Eszoa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets  # for vscode\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "R8M_V5WNiY8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade urllib3==1.26.7\n",
        "!pip install --upgrade awscli==1.22.26\n",
        "!pip install --upgrade botocore==1.23.26"
      ],
      "metadata": {
        "id": "OQFBFUuUNjsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install fastprogress\n",
        "!pip install attrdict"
      ],
      "metadata": {
        "id": "sLM7eOO269-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "from tqdm.notebook import tqdm\n",
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "import numpy as np\n",
        "from transformers import BertForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
      ],
      "metadata": {
        "id": "KdjYuAG2JkRT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'beomi/kcbert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "wQAJotOF7heQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    tokenized_examples = tokenizer(str(examples[\"문장\"]))\n",
        "    tokenized_examples['labels'] = torch.tensor(examples[\"labels\"], dtype=torch.float)\n",
        "    # multi label classification 학습을 위해선 label이 float 형태로 변형되어야 합니다.\n",
        "    # huggingface datasets 최신 버전에는 'map' 함수에 버그가 있어서 변형이 올바르게 되지 않습니다.\n",
        "    \n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "0k2aP29oRkWB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function)\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask', 'token_type_ids'])"
      ],
      "metadata": {
        "id": "qD83_8MERlsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVnyVBhrRp-u",
        "outputId": "18f02375-11e6-497b-bc8c-37e5e81ab552"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'input_ids': tensor([    2,  2458, 15751, 24930, 24351, 29278, 17038, 11631,     3]),\n",
              " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "6lcuU65iN7Aq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels=len(unsmile_labels) # Label 갯수\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=num_labels, \n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "model.config.id2label = {i: label for i, label in zip(range(num_labels), unsmile_labels)}\n",
        "model.config.label2id = {label: i for i, label in zip(range(num_labels), unsmile_labels)}"
      ],
      "metadata": {
        "id": "1bA6SEAbRvsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLxtn9hbR0Qd",
        "outputId": "53f05c5c-d65b-4597-b6e5-ede0cd002d56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean': 9,\n",
              " '기타 혐오': 7,\n",
              " '남성': 1,\n",
              " '성소수자': 2,\n",
              " '악플/욕설': 8,\n",
              " '여성/가족': 0,\n",
              " '연령': 4,\n",
              " '인종/국적': 3,\n",
              " '종교': 6,\n",
              " '지역': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import label_ranking_average_precision_score"
      ],
      "metadata": {
        "id": "Da52OFIlXQOl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(x):\n",
        "    return {\n",
        "        'lrap': label_ranking_average_precision_score(x.label_ids, x.predictions),\n",
        "    }"
      ],
      "metadata": {
        "id": "1MN-aeNJXQMq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "g3Ic83lCXQGo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"model_output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='lrap',\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, \n",
        "    args=args, \n",
        "    train_dataset=tokenized_dataset[\"train\"], \n",
        "    eval_dataset=tokenized_dataset[\"valid\"], \n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "JPVkR9KVXUph"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "FHVPfz4lXUnm",
        "outputId": "44da537a-72d2-473e-9e74-253c59657237"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오. If 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15005\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 938\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [938/938 5:12:25, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Lrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.869759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.194800</td>\n",
              "      <td>0.125699</td>\n",
              "      <td>0.878762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오. If 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3737\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to model_output/checkpoint-469\n",
            "Configuration saved in model_output/checkpoint-469/config.json\n",
            "Model weights saved in model_output/checkpoint-469/pytorch_model.bin\n",
            "tokenizer config file saved in model_output/checkpoint-469/tokenizer_config.json\n",
            "Special tokens file saved in model_output/checkpoint-469/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오. If 여성/가족, 남성, 지역, 종교, 개인지칭, clean, 악플/욕설, 연령, 문장, 인종/국적, 성소수자, 기타 혐오 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3737\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to model_output/checkpoint-938\n",
            "Configuration saved in model_output/checkpoint-938/config.json\n",
            "Model weights saved in model_output/checkpoint-938/pytorch_model.bin\n",
            "tokenizer config file saved in model_output/checkpoint-938/tokenizer_config.json\n",
            "Special tokens file saved in model_output/checkpoint-938/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from model_output/checkpoint-938 (score: 0.8787622488117546).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=938, training_loss=0.15797887529645646, metrics={'train_runtime': 18762.6769, 'train_samples_per_second': 1.599, 'train_steps_per_second': 0.05, 'total_flos': 871448892079332.0, 'train_loss': 0.15797887529645646, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "wLH1r2CpXZTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **✔️ 6. Chance Level 이 넘는지 확인**\n",
        "\n",
        "> Chance Level 0.25를 넘는 것으로 확인 되었다.\n",
        "\n"
      ],
      "metadata": {
        "id": "0lc9AlptzwX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔍 7. 모델 검증(Validation)**"
      ],
      "metadata": {
        "id": "wL78A8M5z2ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    device=-1,\n",
        "    return_all_scores=True,\n",
        "    function_to_apply='sigmoid'\n",
        "    )"
      ],
      "metadata": {
        "id": "keO8uM9jR72p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicated_label(output_labels, min_score):\n",
        "    labels = []\n",
        "    for label in output_labels:\n",
        "        if label['score'] > min_score:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "hl8mUwdkXcTI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from transformers.pipelines.base import KeyDataset\n",
        "\n",
        "predicated_labels = []\n",
        "\n",
        "for out in tqdm.tqdm(pipe(KeyDataset(dataset['valid'], '문장'))):\n",
        "    predicated_labels.append(get_predicated_label(out, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uSKTnfsXhki",
        "outputId": "46fad58f-63d2-4f4e-c579-fb5df1933184"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n",
            "100%|██████████| 3737/3737 [08:17<00:00,  7.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(dataset['valid']['labels'], predicated_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZxYHHsuXh3C",
        "outputId": "e8f407bb-233c-44d7-b64f-40b2bb51024d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.80       394\n",
            "           1       0.87      0.83      0.85       334\n",
            "           2       0.89      0.81      0.84       280\n",
            "           3       0.85      0.80      0.82       426\n",
            "           4       0.88      0.82      0.85       146\n",
            "           5       0.88      0.90      0.89       260\n",
            "           6       0.87      0.88      0.87       290\n",
            "           7       0.86      0.09      0.16       134\n",
            "           8       0.76      0.60      0.68       786\n",
            "           9       0.78      0.72      0.75       935\n",
            "\n",
            "   micro avg       0.82      0.74      0.78      3985\n",
            "   macro avg       0.84      0.72      0.75      3985\n",
            "weighted avg       0.82      0.74      0.76      3985\n",
            " samples avg       0.76      0.74      0.75      3985\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}