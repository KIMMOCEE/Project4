{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ“Š 1. ê´€ì‹¬ ë°ì´í„° ì„ ì •**\n",
        "\n",
        "> Smilegate AIì—ì„œ underscoreì™€ í˜‘ì—…í•˜ì—¬ ë§Œë“  ë°ì´í„°ì…‹ì¸ Korean UnSmile Datasetì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "(https://github.com/smilegate-ai/korean_unsmile_dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R9xcxROOyBWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **â“ 2. ë°ì´í„° ì„ ì • ì´ìœ **\n",
        "\n",
        "*   ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ìµëª…ì„±ê³¼ í‘œí˜„ì˜ ììœ  ë’¤ì— ìˆ¨ì–´ ì•…ì˜ì ì¸ ë°œì–¸ìœ¼ë¡œ ìƒëŒ€ë¥¼ ê³µê²©ì´ ì´ì „ì— ì£¼ëœ ì•…ì„± ëŒ“ê¸€ì´ì—ˆë‹¤ë©´ í˜„ì¬ëŠ” ë¶ˆíŠ¹ì • ë‹¤ìˆ˜ì¸ íŠ¹ì • ì§‘ë‹¨ì— ëŒ€í•œ í˜ì˜¤ í‘œí˜„ ì‚¬ìš©ê¹Œì§€ ì§„í–‰ë˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.\n",
        "*   ì „ìì˜ ê²½ìš° í”¼í•´ìì—ê² í° ì •ì‹ ì  ê³ í†µì´, í›„ìì˜ ê²½ìš° ë¶„ë³„ì—†ëŠ” ìˆ˜ìš©ì™€ ì „íŒŒë¡œ ì¸í•œ ì‚¬íšŒì  ì¸ì‹ ë³€í™”ë¡œ ì¸í•´ ì§‘ë‹¨ ì „ì²´ê°€ í”¼í•´ë¥¼ ë´…ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "> í˜„ì¬ ì‚¬ìš©ë˜ëŠ” í˜ì˜¤í‘œí˜„ë“¤ì€ ì˜ë¯¸ì—†ëŠ” ê°ˆë“±ê³¼ í˜ì˜¤ì˜ ì¬ìƒì‚°ì„ ë§Œë“¤ì–´ë‚´ ì‚¬íšŒì ìœ¼ë¡œ í° ì•…ì˜í–¥ì„ ë¼ì¹˜ëŠ”ë° ì´ëŠ” í¬í„¸ì‚¬ì´íŠ¸, ê²Œì„, ì˜ìƒì œì‘ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œì˜ ì»¨í…ì¸ ë‚˜ ì„œë¹„ìŠ¤ì—ì„œë„ ë¬¸ì œê°€ ë˜ëŠ” ê²ƒì„ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "r8l6Ijdyzbei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ§© 3. ë°ì´í„°ë¥¼ ì´ìš©í•œ ê°€ì„¤ ìˆ˜ë¦½**\n",
        "\n",
        "> ì•…ì„± ëŒ“ê¸€ / í˜ì˜¤ í‘œí˜„ì„ ì‚¬ì „ì— ê²€ì¶œ, ì°¨ë‹¨í•¨ìœ¼ë¡œì¨, ì‚¬íšŒì  ë¬¸ì œì— ëŒ€í•œ ê¸°ì—…ì˜ ì±…ì„ ë¬¸ì œ í•´ê²°ê³¼ ì„œë¹„ìŠ¤ì˜ í’ˆì§ˆ í–¥ìƒì„ ê¸°ëŒ€í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "vKSLgaAGzfjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ§¹ 4. ë°ì´í„° ì „ì²˜ë¦¬**\n",
        "\n",
        "\n",
        "\n",
        "> 1ë²ˆì˜ ê¹ƒí—™ ë§í¬ì— ë“¤ì–´ê°€ì‹œë©´ ë°ì´í„°ì— ëŒ€í•œ ë§ì€ ì •ë³´ë¥¼ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "-N5KD_GoziHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets==1.17.0"
      ],
      "metadata": {
        "id": "GEBZWLnEJRNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('smilegate-ai/kor_unsmile')"
      ],
      "metadata": {
        "id": "eSpWkGuCfhGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISnlqnetJ5Bd",
        "outputId": "b0bf9374-f944-448f-d4ab-8e3d3b7f2f87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean': 1,\n",
              " 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " 'ê°œì¸ì§€ì¹­': 0,\n",
              " 'ê¸°íƒ€ í˜ì˜¤': 0,\n",
              " 'ë‚¨ì„±': 0,\n",
              " 'ë¬¸ì¥': 'ì¼ì•ˆí•˜ëŠ” ì‹œê°„ì€ ì‰¬ê³ ì‹¶ì–´ì„œ ê·¸ëŸ°ê²Œ ì•„ë‹ê¹Œ',\n",
              " 'ì„±ì†Œìˆ˜ì': 0,\n",
              " 'ì•…í”Œ/ìš•ì„¤': 0,\n",
              " 'ì—¬ì„±/ê°€ì¡±': 0,\n",
              " 'ì—°ë ¹': 0,\n",
              " 'ì¸ì¢…/êµ­ì ': 0,\n",
              " 'ì¢…êµ': 0,\n",
              " 'ì§€ì—­': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsmile_labels = [\"ì—¬ì„±/ê°€ì¡±\",\"ë‚¨ì„±\",\"ì„±ì†Œìˆ˜ì\",\"ì¸ì¢…/êµ­ì \",\"ì—°ë ¹\",\"ì§€ì—­\",\"ì¢…êµ\",\"ê¸°íƒ€ í˜ì˜¤\",\"ì•…í”Œ/ìš•ì„¤\",\"clean\"]"
      ],
      "metadata": {
        "id": "Z4y3sTXNJcoc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05AwBZ5SUzZF",
        "outputId": "81c01a10-f27d-4d9f-896b-cd779f2a177e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (15005, 13), 'valid': (3737, 13)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ§  5. ë”¥ëŸ¬ë‹ ë°©ì‹ ì ìš©**"
      ],
      "metadata": {
        "id": "F4wGA5Eszoa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets  # for vscode\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "R8M_V5WNiY8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade urllib3==1.26.7\n",
        "!pip install --upgrade awscli==1.22.26\n",
        "!pip install --upgrade botocore==1.23.26"
      ],
      "metadata": {
        "id": "OQFBFUuUNjsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install fastprogress\n",
        "!pip install attrdict"
      ],
      "metadata": {
        "id": "sLM7eOO269-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "from tqdm.notebook import tqdm\n",
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "import numpy as np\n",
        "from transformers import BertForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
      ],
      "metadata": {
        "id": "KdjYuAG2JkRT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'beomi/kcbert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "wQAJotOF7heQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    tokenized_examples = tokenizer(str(examples[\"ë¬¸ì¥\"]))\n",
        "    tokenized_examples['labels'] = torch.tensor(examples[\"labels\"], dtype=torch.float)\n",
        "    # multi label classification í•™ìŠµì„ ìœ„í•´ì„  labelì´ float í˜•íƒœë¡œ ë³€í˜•ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    # huggingface datasets ìµœì‹  ë²„ì „ì—ëŠ” 'map' í•¨ìˆ˜ì— ë²„ê·¸ê°€ ìˆì–´ì„œ ë³€í˜•ì´ ì˜¬ë°”ë¥´ê²Œ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "    \n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "0k2aP29oRkWB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function)\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask', 'token_type_ids'])"
      ],
      "metadata": {
        "id": "qD83_8MERlsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVnyVBhrRp-u",
        "outputId": "18f02375-11e6-497b-bc8c-37e5e81ab552"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'input_ids': tensor([    2,  2458, 15751, 24930, 24351, 29278, 17038, 11631,     3]),\n",
              " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "6lcuU65iN7Aq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels=len(unsmile_labels) # Label ê°¯ìˆ˜\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=num_labels, \n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "model.config.id2label = {i: label for i, label in zip(range(num_labels), unsmile_labels)}\n",
        "model.config.label2id = {label: i for i, label in zip(range(num_labels), unsmile_labels)}"
      ],
      "metadata": {
        "id": "1bA6SEAbRvsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLxtn9hbR0Qd",
        "outputId": "53f05c5c-d65b-4597-b6e5-ede0cd002d56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean': 9,\n",
              " 'ê¸°íƒ€ í˜ì˜¤': 7,\n",
              " 'ë‚¨ì„±': 1,\n",
              " 'ì„±ì†Œìˆ˜ì': 2,\n",
              " 'ì•…í”Œ/ìš•ì„¤': 8,\n",
              " 'ì—¬ì„±/ê°€ì¡±': 0,\n",
              " 'ì—°ë ¹': 4,\n",
              " 'ì¸ì¢…/êµ­ì ': 3,\n",
              " 'ì¢…êµ': 6,\n",
              " 'ì§€ì—­': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import label_ranking_average_precision_score"
      ],
      "metadata": {
        "id": "Da52OFIlXQOl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(x):\n",
        "    return {\n",
        "        'lrap': label_ranking_average_precision_score(x.label_ids, x.predictions),\n",
        "    }"
      ],
      "metadata": {
        "id": "1MN-aeNJXQMq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "g3Ic83lCXQGo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"model_output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='lrap',\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, \n",
        "    args=args, \n",
        "    train_dataset=tokenized_dataset[\"train\"], \n",
        "    eval_dataset=tokenized_dataset[\"valid\"], \n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "JPVkR9KVXUph"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "FHVPfz4lXUnm",
        "outputId": "44da537a-72d2-473e-9e74-253c59657237"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤. If ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15005\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 938\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [938/938 5:12:25, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Lrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.869759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.194800</td>\n",
              "      <td>0.125699</td>\n",
              "      <td>0.878762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤. If ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3737\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to model_output/checkpoint-469\n",
            "Configuration saved in model_output/checkpoint-469/config.json\n",
            "Model weights saved in model_output/checkpoint-469/pytorch_model.bin\n",
            "tokenizer config file saved in model_output/checkpoint-469/tokenizer_config.json\n",
            "Special tokens file saved in model_output/checkpoint-469/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤. If ì—¬ì„±/ê°€ì¡±, ë‚¨ì„±, ì§€ì—­, ì¢…êµ, ê°œì¸ì§€ì¹­, clean, ì•…í”Œ/ìš•ì„¤, ì—°ë ¹, ë¬¸ì¥, ì¸ì¢…/êµ­ì , ì„±ì†Œìˆ˜ì, ê¸°íƒ€ í˜ì˜¤ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3737\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to model_output/checkpoint-938\n",
            "Configuration saved in model_output/checkpoint-938/config.json\n",
            "Model weights saved in model_output/checkpoint-938/pytorch_model.bin\n",
            "tokenizer config file saved in model_output/checkpoint-938/tokenizer_config.json\n",
            "Special tokens file saved in model_output/checkpoint-938/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from model_output/checkpoint-938 (score: 0.8787622488117546).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=938, training_loss=0.15797887529645646, metrics={'train_runtime': 18762.6769, 'train_samples_per_second': 1.599, 'train_steps_per_second': 0.05, 'total_flos': 871448892079332.0, 'train_loss': 0.15797887529645646, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "wLH1r2CpXZTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **âœ”ï¸ 6. Chance Level ì´ ë„˜ëŠ”ì§€ í™•ì¸**\n",
        "\n",
        "> Chance Level 0.25ë¥¼ ë„˜ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ ë˜ì—ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "0lc9AlptzwX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ” 7. ëª¨ë¸ ê²€ì¦(Validation)**"
      ],
      "metadata": {
        "id": "wL78A8M5z2ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    device=-1,\n",
        "    return_all_scores=True,\n",
        "    function_to_apply='sigmoid'\n",
        "    )"
      ],
      "metadata": {
        "id": "keO8uM9jR72p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicated_label(output_labels, min_score):\n",
        "    labels = []\n",
        "    for label in output_labels:\n",
        "        if label['score'] > min_score:\n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "hl8mUwdkXcTI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from transformers.pipelines.base import KeyDataset\n",
        "\n",
        "predicated_labels = []\n",
        "\n",
        "for out in tqdm.tqdm(pipe(KeyDataset(dataset['valid'], 'ë¬¸ì¥'))):\n",
        "    predicated_labels.append(get_predicated_label(out, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uSKTnfsXhki",
        "outputId": "46fad58f-63d2-4f4e-c579-fb5df1933184"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3737/3737 [08:17<00:00,  7.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(dataset['valid']['labels'], predicated_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZxYHHsuXh3C",
        "outputId": "e8f407bb-233c-44d7-b64f-40b2bb51024d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.80       394\n",
            "           1       0.87      0.83      0.85       334\n",
            "           2       0.89      0.81      0.84       280\n",
            "           3       0.85      0.80      0.82       426\n",
            "           4       0.88      0.82      0.85       146\n",
            "           5       0.88      0.90      0.89       260\n",
            "           6       0.87      0.88      0.87       290\n",
            "           7       0.86      0.09      0.16       134\n",
            "           8       0.76      0.60      0.68       786\n",
            "           9       0.78      0.72      0.75       935\n",
            "\n",
            "   micro avg       0.82      0.74      0.78      3985\n",
            "   macro avg       0.84      0.72      0.75      3985\n",
            "weighted avg       0.82      0.74      0.76      3985\n",
            " samples avg       0.76      0.74      0.75      3985\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}